# Topic-Modelling
Topic Modelling for Customer Reviews on Yelp

Dataset Source: Kaggle

Team Members: Shashank Jain Aastha Patel Shreshtha Mankala Sumit Lakhawat Devna Ramesh

Abstract

As more and more raw data is generated by users and corporation over the internet there is a need for a mechanism to summarize that data in few topics. Topic modeling is a method which separate sentences or documents based on theme, in our project we have used to find the key topics among the customer reviews for a particular business. We have used Bert Topic for the purpose and later added sentiment analysis to link topic and sentiments of the user to be used as actionable insight.

INTRODUCTION

1.1 Topic Modeling

Digital platforms have changed the way we live our lives. It is possible that any product or service that we end up buying is a response to some review that we had read online. The social media savvy consumers do not shy away from leaving feedback online, which can possibly affect the customer pool of businesses.
This has compelled companies to spend time and money to monitor these comments and leverage these comments as sources for improvement. Many businesses are moving toward a data driven decision making process where they rely on customer analytics.
We use NLP to analyze customer reviews that could allow companies to better understand diverse customer preferences and improve product design, manufacturing processes and marketing campaigns. In our project we have tried to build a model which summarizes the key topics in the reviews and also assign a sentiment score against each topic, which provides actionable insights to the business.

1.2 Topic Modeling and Dataset

Topic Modeling is a probabilistic generative model that has been used widely for text mining and information retrieval in recent years. The ultimate goal of topic modeling to find a theme across reviews and discover hidden topics. Each review will be assigned at least one topic depending on its probability.
The dataset that we have chosen for the project is a subset of Yelp's businesses, reviews, and user data. We have used the below json files, obtained from Yelp academic dataset available on Kaggle (yelp_academic_dataset_business.json, yelp_academic_dataset_review.json)

Yelp is a review platform that allows users to provide ratings and text based reviews for local businesses. It has more than 178 million users visiting across desktop, mobile and app platforms. With more than 7 million reviews submitted on the platform, Yelp has become one of the key resources not just for users who use it to decide on which product or service to go with, but also for local businesses to analyze their product ratings and gross sales.

1.3 Objective

Our goal for the project is to solve a problem faced by all corporations dealing with a large customer base and providing any kind of service. To build better products, organizations need to focus on feedback and suggestion from customers. Therefore, companies love to collect feedback from their customers but processing them is not easy and it is not possible to manually read those texts and summarize them in actionable insights for a rapidly increasing data. Advancement in NLP has solved this problem a little bit. We can make a model that could identify the most relevant topics of a particular business and conclude the sentiment associated with it to understand what aspects of the business are appealing to the users and the areas that need work.
Product features discussed in textual reviews are combined with the sentiment orientation of user ratings to discover the associations between market segments, topical aspects, and sentiments.


METHODOLOGY

2.1 Overview of BERTopic

Bert model takes advantage of the superior language capabilities of transformer model and use ML techniques like UMAP, HDBSCAN. Unlike other famous topic modeling method such as LDA, it has an advantage of using pretrained sentence transformers to create embeddings of the given data that saves sentences from losing the context and can be able to differentiate a similar word based on context.
The four key components of a BERT model are as follows:
• Transformer embedding model
• UMAP dimensionality reduction
• HDBSCAN clustering
• Cluster tagging using c-TF-IDF
A typical Bertopic model returns 2 lists:
• Topics – one to one mapping of inputs to modelled topics or clusters
• Probability distribution – List of probabilities that an input belongs to the assigned topic

There are various sentence transformer available for different languages. We started with one of the default sentence transformers available with the Bertopic library in python all-minilm-l6-v2. It was built by huggingface on 1 billion pairs of data. It generates a 384-dimension output for the given sentence. It also trims any sentence which is bigger than 156 words. The results that we got are not that great therefore we moved to another sentence transformer xlm-r-bert-base-nli-stsb-mean-tokens. This generates embedded vector of 768-dimensional dense vector space. We have used this one as the final choice as running the code from start was a time-consuming task.
As the output from the embedding step is of high dimension, we need to apply dimension reduction method. The default algorithm used in Bertopic package in python is UMAP
It treats data as weighted graph, where each data point is represented as a node, and the edges between nodes represent the distances between points. The reduce dimension help the next step of clustering by reducing the complexities introduced by high dimension and most of the clustering algorithm doesn’t work well with such high dimensions.

The default algorithm for doing clustering in dataset is HDBSCAN. HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise) is a density- based clustering algorithm that can identify clusters of different sizes and shapes in a dataset. It is an extension of the DBSCAN algorithm, which is one of the most popular density-based clustering methods. HDBSCAN works by recursively applying DBSCAN to different levels of the hierarchy, and it can identify clusters of varying densities without the need for the user to specify a density threshold. The output from this helps identifying the theme or pattern in the given data. Based on the output from cluster we group the data in the similar topics.
In the end to find the most relevant words from the clusters that is created in the previous step we use TF-IDF. TF-IDF works by first calculate the term frequency in each sentence and finding the frequency of that word in whole document. Through this we can find the importance o each term in a particular cluster and could be used as topic labels.

2.2 Sentiment Analysis

As topic found through the algorithms like Bert-topic does not help with knowing the sentiment associated with the topic it’s very important to find the sentiments around each topic so business could use it their decision making on improving the business.
For our project we have used python package call Vader for the purpose o finding the sentiment around the all the topics. VADER (Valence Aware Dictionary and Sentiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. It is able to take into account the nuances of natural language, including the use of emojis, capitalization, and punctuation, to accurately predict the sentiment of a given piece of text. To perform sentiment analysis with VADER, the text is first tokenized into individual words and punctuation, and then each token is scored based on its presence in VADER's lexicon of words with known sentiment scores. These scores are then combined to compute the overall sentiment of the text, which can be positive, negative, or neutral.

DATA PREPROCESSING

As we had a large file of size 5.5 GB that contains all the customer reviews, we decided use Kaggle sandbox as it provide large memory size of 30 GB. We than decided to just keep two columns that would be useful in model building.i.e. business_id and reviews . That helped us to reduce the size, we also read the file in chunks so we don’t consume he whole memory available to us.
As the Bertopic package have out of the box functionality of using GPU provided available, we ran our code by using free GPU units available in Google Collab that in comparison of CPU gave boost to speed and made our code 10 times faster approx.
We also removed stop words from our datasets against the general belief to keep them as it helped sentence transformer to understand the context, but we were seeing many stop words making appearance in our topic labels ad used n_gram value two as it’s enough to considers words pairs to understand the context for our given dataset.
<img width="800" alt="image" src="https://user-images.githubusercontent.com/126206486/222933222-84456560-e4d4-4d31-8701-ffc41fe433b8.png">

We also removed stop words from our datasets against the general belief to keep them as it helped sentence transformer to understand the context, but we were seeing many stop words making appearance in our topic labels ad used n_gram value two as it’s enough to considers words pairs to understand the context for our given dataset.
We build our model based on keeping the top words equal to 3 and limiting the number of topics to 5 and we also used the sentence transformer language to just English as we had majority of our data in English except some outliers reviews in Spanish.

RESULT

4.1 Topic Analysis per Business

1. Acme Oysters House
    <img width="478" alt="image" src="https://user-images.githubusercontent.com/126206486/222933257-f7b1710b-4128-4bd8-a5d6-788f17b26849.png">


Analysed the first five topics that was extracted from the reviews.
From the topics, we can see the most talked about and hence, the most relevant topic is the “char grilled oysters”, which on further research was found out to be the one of the best-selling dishes of this restaurant. Apart from this the location of this business unit can also be concluded as one of the most important topics contributing to the gross sales of the business- ‘NOLA’ or ‘New Orleans’ topics mentioned above. One of the topics, talk about the ‘line’ indicating that there could be a long waiting time at the restaurant. But the topic has the key word ‘worth’ as well which insinuates that the the ‘good food’ is ‘worth’ the ‘line’
<img width="343" alt="image" src="https://user-images.githubusercontent.com/126206486/222933263-01cdacc6-ad9a-4d11-9e15-eebc9e4b52cc.png">
The above visualization generated by the built-in visualization method, visualize_hierarchy, helps us to understand the similarity between the generated topics. In this case, we realize that topics 1 and 2 are talking about the location of the business unit and hence it will be in the same quadrant of the graph. It’s the same case with topics, 3 and 5 that talks about the char-grilled oysters, which would end up in the other quadrant. This helps us to remove any redundancy in the topic analysis.

<img width="355" alt="image" src="https://user-images.githubusercontent.com/126206486/222933285-c9cf1c38-3b6e-49c3-a2d4-84d1dcb8daa7.png">

The above visualization uses the visualization method, visualize_barchart, that gives the probability distribution of the generated topics. It provides the probability of a particular review belonging to one of the generated topics. This can be used to conclude the most relevant topic in the customer reviews.

2. Hattie B’s Hot Chicken

The extracted topics reveal the top bestselling dishes of the restaurant- hot chicken, mac n cheese and banana pudding.
<img width="498" alt="image" src="https://user-images.githubusercontent.com/126206486/222933303-85d94101-5f0e-49fb-8eac-cb8d20d62e3e.png">
<img width="390" alt="image" src="https://user-images.githubusercontent.com/126206486/222933314-6430482d-a817-4d0f-8469-f64517c10ab2.png">

   
This has classified the reviews into two main categories based on the probability distribution with majority of the reviews talking about the restaurant having great food and the second set talking about the location indicating that they have the best chicken in Nashville.

3. Reader Farming Market
<img width="549" alt="image" src="https://user-images.githubusercontent.com/126206486/222933323-5b91b3da-68da-41df-aa28-f2bb33ba250f.png">

Unlike the last two businesses, this particular business doesn’t focus on a particular dish(chicken or oysters like the previous ones). Hence the topics revolve around ‘great food’ and ‘great place in Philadelphia’.
 <img width="530" alt="image" src="https://user-images.githubusercontent.com/126206486/222933329-1d9efe15-4969-4b8b-9bc4-6d2bc74cdcba.png">

The above visuals gives the similarity of topics and its probability distribution.

4.2 Sentiment Analysis per Business

1. Acme Oysters House
The sentiment score obtained against all the topics are inclined to a positive rate, indicating that the business is doing well.
<img width="496" alt="image" src="https://user-images.githubusercontent.com/126206486/222933343-f537438a-7571-4a84-bcfc-07c91c0b9027.png">

2. Hattie B’s Hot Chicken
<img width="604" alt="image" src="https://user-images.githubusercontent.com/126206486/222933355-2acf304d-d099-4035-a0a6-c0cc7c0c2731.png">

   
3. Reader Farming Market
<img width="543" alt="image" src="https://user-images.githubusercontent.com/126206486/222933362-85853d86-65c1-49e4-a587-fbaf81e8ded8.png">

   
CONCLUSION

To conclude, our aim was to find some relevant topics that the customers are talking about through their reviews. We created a model that could determine the most important business themes and analyze the sentiment linked with it to determine what features of the product/service of the company appeal to customers and what needs improvement. We used the most comprehensive review website available for this, yelp.com. It provided us with more than sufficient data to apply our model on and generate credible results. Topic modelling gave us the most relevant topics that eople are talking about based on their reviews, but just finding out the topics does not make sense for a business. To extract some knowledge from this information, we performed sentiment analysis on the topics found to understand the mood of the customers about that topic. Since, we used real world data, the insights gained are something that can be used by the companies to understand their businesses better. For now, we just used two sentence transformers- used for embedding in bertopic model, we can explore more in the future which can help us to fine tune the performance of the model.

CONTRIBUTIONS

Research and Data Wrangling BERTopic Model
Model Testing and Tuning Sentiment Analysis Documentation

REFERENCES

1) Dataset source https://www.kaggle.com/datasets/yelp-dataset/yelp-dataset
2) Ilhan, Ahmet & Durmaz, Yakup. (2015). Growth Strategies in Busınesses and A Theoretical
Approach. International Journal of Business and Management. 10. 210- 214.https://www.researchgate.net/publication/283644997_Growth_Strategies_in_Businesses_an d_A_Theoretical_Approach
3) Lunkad, Kartik. (2015). Prediction of Yelp Rating using Yelp Reviews.https://www.researchgate.net/publication/280102160_Prediction_of_Yelp_Rating_usin g_Yelp_Reviews
4) Liu, L., Tang, L., Dong, W. et al. An overview of topic modeling and its current applications in bioinformatics. SpringerPlus 5, 1608 (2016). https://doi.org/10.1186/s40064-016-3252-8
5) Maarten Grootendorst. BERTopic: Neural topic modeling with a class-based TF-IDF procedure.
(March 2022). https://arxiv.org/abs/2203.05794
6) Hutto, C.J. & Gilbert, E.E. 2014. VADER: A Parsimonious Rule Rule-Based Model for Sentiment
Analysis of Social Media Text. https://ojs.aaai.org/index.php/ICWSM/article/view/14550
